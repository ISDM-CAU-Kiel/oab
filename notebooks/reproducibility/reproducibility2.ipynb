{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWTe3BI5Gfyz"
   },
   "source": [
    "This notebook focuses on how unique preprocessing can be applied to a dataset and recorded in the `yaml` file, making it easily reproducible.\n",
    "\n",
    "\n",
    "The notebook `Reproducibility1.ipynb` shows how `oab` can generally be used to make results easily reproducible, ranging from preprocessing over converting the dataset into an anomaly dataset and finally sampling from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "liLAM3RxGRMC"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3K2vYiLgddk"
   },
   "source": [
    "The unique preprocessing in this example is simply a scaling operation for all data points. (Note: This can be handled in `oab` using the `ClassificationDataset.scale()` operation. As it is a simple operation, it is used in this example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwlh--JggdBc",
    "outputId": "c2082065-3c97-489b-b5cd-fffe97bb6278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def scale_values(values: np.ndarray, scaling_factor: float, message: str):\n",
      "    print(message)\n",
      "    return values * scaling_factor\n"
     ]
    }
   ],
   "source": [
    "# download custom preprocessing function and inspect content\n",
    "import wget\n",
    "wget.download('https://raw.githubusercontent.com/jandeller/test/main/custom_preprocessing.py', \"custom_preprocessing.py\")\n",
    "!cat custom_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbX7VD1ujUbc"
   },
   "source": [
    "**Note that the first parameter has to the `X` values of the dataset**, as this is automatically passed as first argument when calling custom preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrEGFgriikPI"
   },
   "source": [
    "In `Reproducibility1.ipynb` (LINK HERE), it was shown how a `yaml` file that records all changes applied to a dataste is created. The custom preprocessing steps are added manually to that file by specifying the operation's name and parameters. In this case, the following would be added to the `yaml` file:\n",
    "\n",
    "```\n",
    "custom_functions:\n",
    "  - name: scale_values\n",
    "    parameters:\n",
    "      scaling_factor: 0.5\n",
    "      message: \"Scaled all values by factor 0.5.\"\n",
    "```\n",
    "\n",
    "We next download a `yaml` file with this content.\n",
    "Then, a dataset is loaded as classification dataset without any preprocessing applied to it, and the preprocessing step described in the `yaml` file, i.e., the custom scaling function, is applied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC1wc5LfiQVC",
    "outputId": "182f3a38-4b83-43c7-f886-4c4524766dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_functions:\n",
      "  - name: scale_values\n",
      "    parameters:\n",
      "      scaling_factor: 0.5\n",
      "      message: \"Scaled all values by factor 0.5.\"\n"
     ]
    }
   ],
   "source": [
    "# download yaml and inspect content\n",
    "import wget\n",
    "wget.download('https://raw.githubusercontent.com/jandeller/test/main/custom_preprocessing_config.yaml', \"custom_preprocessing_config.yaml\")\n",
    "!cat custom_preprocessing_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJHYyiAgkMFf",
    "outputId": "f0c37536-b91e-4d57-d0dc-322845bb79d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credits: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n"
     ]
    }
   ],
   "source": [
    "# load dataset (as classification dataset without any preprocessing applied)\n",
    "from oab.data.load_dataset import load_dataset\n",
    "wilt_cd = load_dataset('wilt', anomaly_dataset=False, preprocess_classification_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcskR7d_kMHk",
    "outputId": "f099c37a-a471-46f0-ba02-0fe4aee293a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120.3627737 , 205.5       , 119.3953488 , 416.5813953 ,\n",
       "         20.67631835],\n",
       "       [124.7395833 , 202.8       , 115.3333333 , 354.3333333 ,\n",
       "         16.70715083],\n",
       "       [134.6919643 , 199.2857143 , 116.8571429 , 477.8571429 ,\n",
       "         22.49671178],\n",
       "       ...,\n",
       "       [119.0766871 , 247.9512195 , 113.3658537 , 808.0243902 ,\n",
       "         24.83005893],\n",
       "       [107.9444444 , 197.        ,  90.        , 451.        ,\n",
       "          8.2148874 ],\n",
       "       [119.7319277 , 182.2380952 ,  74.28571429, 301.6904762 ,\n",
       "         22.94427836]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect values from wilt dataset\n",
    "wilt_cd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4_BkHnpkMJz",
    "outputId": "89727ab2-5532-40ea-e358-fc99078d70a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled all values by factor 0.5.\n"
     ]
    }
   ],
   "source": [
    "wilt_cd.perform_operations_from_yaml(filepath=\"custom_preprocessing_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5nQAx5okoyk",
    "outputId": "5f12d006-c1cd-4ce6-bf17-7839c78d970b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60.18138685, 102.75      ,  59.6976744 , 208.29069765,\n",
       "         10.33815917],\n",
       "       [ 62.36979165, 101.4       ,  57.66666665, 177.16666665,\n",
       "          8.35357541],\n",
       "       [ 67.34598215,  99.64285715,  58.42857145, 238.92857145,\n",
       "         11.24835589],\n",
       "       ...,\n",
       "       [ 59.53834355, 123.97560975,  56.68292685, 404.0121951 ,\n",
       "         12.41502946],\n",
       "       [ 53.9722222 ,  98.5       ,  45.        , 225.5       ,\n",
       "          4.1074437 ],\n",
       "       [ 59.86596385,  91.1190476 ,  37.14285715, 150.8452381 ,\n",
       "         11.47213918]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect values from wilt dataset -> Scaled by 0.5.\n",
    "wilt_cd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6DFRwqpko0q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reproducibility2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
