{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100a6f8d",
   "metadata": {
    "id": "100a6f8d"
   },
   "source": [
    "\n",
    "## In this notebook, you will see all the steps sequentially performed to be able to utilize the complete functionality of OAB framework. The steps are as follows :\n",
    "0. SETUP\n",
    "1. DATA\n",
    "2. DATA SELECTION\n",
    "3. PREPROCESSING\n",
    "4. SAMPLING\n",
    "5. ALGORITHM TRAINING AND TESTING\n",
    "6. EVALUATION\n",
    "7. SHOW BENCHMARK RESULTS\n",
    "8. REPRODUCIBILTY\n",
    "9. EXTENDING THE BENCHMARK(with own Algorithm)\n",
    "\n",
    "This notebook focuses on <b>Unsupervised Image Data</b>. Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VXCXUMi0bRJA",
   "metadata": {
    "id": "VXCXUMi0bRJA"
   },
   "source": [
    "# **0. SETUP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kkhqUcFybZ56",
   "metadata": {
    "id": "kkhqUcFybZ56"
   },
   "source": [
    "`oab` framework can be integrated in your Python environment  as a PyPi package  using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9rc17bsZbbnb",
   "metadata": {
    "id": "9rc17bsZbbnb"
   },
   "outputs": [],
   "source": [
    "#ID 1(0)\n",
    "\n",
    "#%%capture\n",
    "# pip install oab\n",
    "!pip install example-pkg-jd-kiel --extra-index-url=https://test.pypi.org/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348768e8",
   "metadata": {},
   "source": [
    "`Cloning` the repository:\n",
    "\n",
    "`oab` is an open-source framework which can be accessed at https://github.com/ISDM-CAU-Kiel/oab. To use this .ipynb notebook successfully, the formerly mentioned repository needs to be cloned with the following command and this notebook must be run(if this is not the case already) within the cloned repository from the path:\n",
    "\n",
    "<b>/oab/notebooks/benchmark_image/Unsupervised_Anomaly_Detection_on_Benchmark_Image_Data_V0.3.ipynb</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID 2(0)\n",
    "!git clone https://github.com/ISDM-CAU-Kiel/oab.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29af6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#ID 3(0)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime \n",
    "from pathlib import Path\n",
    "sys.path.append('../..')           \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# necessary imports for loading datasets as well as information from recipe files\n",
    "from oab.data.unsupervised import UnsupervisedAnomalyDataset\n",
    "from oab.data.load_image_dataset import _load_image_dataset\n",
    "from oab.data.load_dataset import load_dataset\n",
    "from oab.data.utils_image import image_datasets\n",
    "from oab.data.load_recipe_functions import *\n",
    "from oab.evaluation import EvaluationObject, ComparisonObject,all_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb70c2",
   "metadata": {
    "id": "50eb70c2"
   },
   "source": [
    "## **0.1 NOTEBOOK AND CELL STRUCTURE** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4cbba",
   "metadata": {
    "id": "bca4cbba"
   },
   "source": [
    "In this notebook there are certain sections where the user is required to enter its own information which are marked as comments of the form :\n",
    "\n",
    "<b>### ADD YOUR CODE ###</b>  , so <b>###</b> can be searched to know what are those sections.\n",
    "\n",
    "All cells are assigned an ID, as a comment at the top of the cell,for example as: <b>#ID 10(5)</b>, where 10 denotes the cell ID and 5 denotes the Section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff9d10",
   "metadata": {},
   "source": [
    "## 0.2 DETAILS OF THIS BENCHMARK RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f316b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220308143458-Paper_A-usi-recipe.yaml\n"
     ]
    }
   ],
   "source": [
    "#ID 4(0)\n",
    "### ADD YOUR BENCHMARK NAME HERE ###\n",
    "benchmark_name=\"Paper_A\" \n",
    "\n",
    "\n",
    "\n",
    "dataset_folder=\"datasets\" # all dataset-folders are contained in this folder\n",
    "#print(dataset_folder)\n",
    "\n",
    "benchmark_type=\"usi\"     # benchmark run for unsupervised image datasets(sst)\n",
    "if not os.path.exists(benchmark_name): #creating directory for this benchhmark for storing recipes\n",
    "    os.makedirs(benchmark_name)\n",
    "\n",
    "    \n",
    "time=datetime.now().strftime(\"%Y%m%d%H%M%S\") # timestamp set for this run  \n",
    "new_recipe_path=f\"{benchmark_name}/{time}-{benchmark_name}-{benchmark_type}-recipe.yaml\" # recipe path for new recipe created in this run   \n",
    "print(f\"{time}-{benchmark_name}-{benchmark_type}-recipe.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c7b61",
   "metadata": {},
   "source": [
    "### For reproducing a previously-created recipe without adding new datasets and algorithms from this benchmark  ,  skip to :\n",
    "\n",
    "### `#ID 20(5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ge7C0gfOXtkJ",
   "metadata": {
    "id": "Ge7C0gfOXtkJ"
   },
   "source": [
    "# **1. DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7714d531",
   "metadata": {
    "id": "7714d531"
   },
   "source": [
    "First of all, we will have a look at the Datasets that are pre-installed in OAB which can be used for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c45b98e",
   "metadata": {
    "id": "1c45b98e",
    "outputId": "de6c3c28-b6c3-4dd5-cf4d-c9dbc018a5fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.mnist\n",
      "1.fashion_mnist\n",
      "2.cifar10\n",
      "3.cifar100\n",
      "4.mvtec_ad_carpet\n",
      "5.mvtec_ad_grid\n",
      "6.mvtec_ad_leather\n",
      "7.mvtec_ad_tile\n",
      "8.mvtec_ad_wood\n",
      "9.mvtec_ad_bottle\n",
      "10.mvtec_ad_cable\n",
      "11.mvtec_ad_capsule\n",
      "12.mvtec_ad_hazelnut\n",
      "13.mvtec_ad_metal_nut\n",
      "14.mvtec_ad_pill\n",
      "15.mvtec_ad_screw\n",
      "16.mvtec_ad_toothbrush\n",
      "17.mvtec_ad_transistor\n",
      "18.mvtec_ad_zipper\n",
      "19.crack\n"
     ]
    }
   ],
   "source": [
    "#ID 5(1)\n",
    "lst_all_datasetnames =image_datasets\n",
    "for i,dataset in enumerate(lst_all_datasetnames):\n",
    "    print(f\"{i}.{dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5GfTylvidJUs",
   "metadata": {
    "id": "5GfTylvidJUs"
   },
   "source": [
    "\n",
    "`oab` provides a variety of image datasets that can easily be loaded, in either of the following ways: \n",
    "\n",
    "`1.` If a user is interested in using her own image dataset  loading **via local folder directory**, the following steps have to be followed: (1) Ensure that the format is readable by oab. This requires there to be a folder for the dataset with the subfolders `normal` and `anomaly`. Naturally, all normal images are in the folder `normal` and all images of anomalies in the folder `anomaly`. (2) Based on this folder structure, the dataset can be loaded.\n",
    "\n",
    "\n",
    "\"**Local folder structure - without URL usage**\" :\n",
    "```\n",
    "dataset_name\n",
    "        │\n",
    "        ├── normal\n",
    "        │    \n",
    "        └── anomaly\n",
    "``` \n",
    "\n",
    "`2.` If user's dataset is provided **via a URL**, then it would be downloaded and stored in the OAB's \"datasets\" folder, given that it is already formatted as per the required folder heirarchy, where the folder :\n",
    "\n",
    "`good`(which should not be renamed) : contains normal images whereas \n",
    "\n",
    "`anomaly_folder_n`(can be renamed):  contains anomalous images\n",
    "\n",
    "\n",
    "\n",
    "\"**Uploaded folder structure - with URL usage**\" :\n",
    "```\n",
    "dataset_name\n",
    "        │\n",
    "        ├── train\n",
    "        │   ├── good\n",
    "        │\n",
    "        │  \n",
    "        └── test\n",
    "            ├── good\n",
    "            ├── anomaly_folder_1\n",
    "            ├── ...\n",
    "            ├── ...\n",
    "            ├── anomaly_folder_2\n",
    "```\n",
    " \n",
    "Note: Alternatively, it is of course possible to load the images into `numpy` arrays and treat them as if they were tabular data. If this approach is to be followed, please look at the notebooks for tabular data.\n",
    "\n",
    "\n",
    "- Notes: Limited to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Jap0jcY8JQwb",
   "metadata": {
    "id": "Jap0jcY8JQwb",
    "outputId": "56d80fce-d7ea-4693-aa71-41e58b766d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset(s) successfully added as :  ['mvtec_ad_myImageDataset']\n",
      "Datasets of OAB:\n",
      "0.mnist\n",
      "1.fashion_mnist\n",
      "2.cifar10\n",
      "3.cifar100\n",
      "4.mvtec_ad_carpet\n",
      "5.mvtec_ad_grid\n",
      "6.mvtec_ad_leather\n",
      "7.mvtec_ad_tile\n",
      "8.mvtec_ad_wood\n",
      "9.mvtec_ad_bottle\n",
      "10.mvtec_ad_cable\n",
      "11.mvtec_ad_capsule\n",
      "12.mvtec_ad_hazelnut\n",
      "13.mvtec_ad_metal_nut\n",
      "14.mvtec_ad_pill\n",
      "15.mvtec_ad_screw\n",
      "16.mvtec_ad_toothbrush\n",
      "17.mvtec_ad_transistor\n",
      "18.mvtec_ad_zipper\n",
      "19.crack\n",
      "20.mvtec_ad_myImageDataset\n"
     ]
    }
   ],
   "source": [
    "#ID 6(1)\n",
    "\n",
    "\n",
    "#### ADD YOUR DATASETNAME(S) HERE ###\n",
    "\n",
    "\n",
    "own_datasets_list=[\"myImageDataset\"]  # More of user's own datasets can be added in this list\n",
    "benchmark_datasets_list=['mvtec_ad_transistor']   # More of OAB's datasets can be added to this list\n",
    "\n",
    "# 'myImageDataset' is the name of the Dataset(which the user loads for benchmarking as well as the name of the folder containing normal and anomaly folders\n",
    "#  which further contain the respective images\n",
    "#  and make sure folder structure is correct ({dataset_folder}/{name-without mvtec_ad_}/[normal/anomaly])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calling the helper function to update internal OAB variables \n",
    "mvtec_ad_own_datasets_list=[]\n",
    "for dataset_name in own_datasets_list:\n",
    "  mvtec_ad_own_datasets_list.append(add_own_dataset(dataset_name))\n",
    "print( f\" Dataset(s) successfully added as :  {mvtec_ad_own_datasets_list}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Now,  we'll have a look at all the datasets again which are pre-installed in OAB,after adding own_datasets \n",
    "lst_all_datasetnames =image_datasets\n",
    "print(\"Datasets of OAB:\")\n",
    "for i,dataset in enumerate(lst_all_datasetnames):\n",
    "    print(f\"{i}.{dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2lQC5bsi87O",
   "metadata": {
    "id": "k2lQC5bsi87O"
   },
   "source": [
    "Now, If this dataset(s) was already stored in the dataset_folder, structured as mentioned in the initial description of this section above, then we have to create the file \"applied_modification.txt\" in Path(dataset_folder)/dataset_name/ \"applied_modification.txt\"). If this is not available in the location, then we download the dataset from the given URL(When data is downloaded for the URL, the orientation of the folders as well as the image resizing operation is performed and  information about that is stored in \"applied_modification.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sQUa14_KqO9C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "sQUa14_KqO9C",
    "outputId": "0c98a9cb-5eef-4107-bed5-04e19aebd23c"
   },
   "outputs": [],
   "source": [
    "#ID 7(1)\n",
    "for dataset_name in own_datasets_list:\n",
    "  open(Path(dataset_folder)/dataset_name/\"applied_modification.txt\", \"w\") \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1bdac",
   "metadata": {
    "id": "c0c1bdac"
   },
   "source": [
    "# **2. DATA SELECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NZ9L0Cc-NPsB",
   "metadata": {
    "id": "NZ9L0Cc-NPsB"
   },
   "source": [
    "\n",
    "Datasets can either be loaded directly as anomaly datasets or as classification datasets. In the former case, the dataset is automatically fully prepared and ready for sampling. In the latter case, further preprocessing is still possible and necessary.\n",
    "\n",
    "Note that the automatic preprocessing for image datasets is to scale each value by `1/255`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11dpL-kh5qX",
   "metadata": {
    "id": "f11dpL-kh5qX"
   },
   "source": [
    "**After adding own dataset(s) in #ID 6(1),the user is able to load own dataset(s) using this method :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BkZNi850qMy6",
   "metadata": {
    "id": "BkZNi850qMy6"
   },
   "outputs": [],
   "source": [
    "#ID 8(2)\n",
    "\n",
    "from oab.data.load_image_dataset import _load_image_dataset\n",
    "datasets={}  # contain dataset objects of own dataset names \n",
    "\n",
    "\n",
    "for dataset_name in mvtec_ad_own_datasets_list:  # loading own datasets \n",
    "    # argument unsupervised=True by default in the dataset-loading function call below\n",
    "    datasets[dataset_name[9:]]=_load_image_dataset(dataset_name ,anomaly_dataset=False,preprocess_classification_dataset=False,dataset_folder=dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jZrY4gxINSqv",
   "metadata": {
    "id": "jZrY4gxINSqv"
   },
   "source": [
    "### **2.1 Load anomaly detection datasets (with or without further preprocessing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1GoNZY8YNSu0",
   "metadata": {
    "id": "1GoNZY8YNSu0"
   },
   "source": [
    "IIn this section, we load some pre-installed data sets. This can be achieved using the `load_dataset` function. By default, it creates an anomaly dataset from which sampling is directly possible  but we can first create classifcation dataset and then anomaly dataset,either with the preprocessing applied (`preprocess_classification_dataset=True`) i.e. Scaling is performed on all values by the factor of 1/255, or without (`preprocess_classification_dataset=False`, default).\n",
    "\n",
    "`In our case` we set have already imported own datasets with `anomaly_dataset=False ` and `preprocess_classification_dataset=False` in <b>#ID 8(2)</b> and we will also load the OAB datasets in the same way in <b>#ID 9(2)</b>\n",
    "\n",
    "\n",
    "Note that as discussed in the paper, multiclass classification datasets like Cifar10 and MNIST are loaded with the class label `0` as normal label and all other labels as anomaly labels by default. (Alternatively, `oab` can automatically iterate through all classes as normal classes. This is not covered here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6VrjgVJANX8V",
   "metadata": {
    "id": "6VrjgVJANX8V",
    "outputId": "2608f64a-9804-41e0-e8be-5656206565d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'myImageDataset': <oab.data.classification_dataset.ClassificationDataset object at 0x7f88300cb590>, 'mvtec_ad_transistor': <oab.data.classification_dataset.ClassificationDataset object at 0x7f87b9fb1050>}\n"
     ]
    }
   ],
   "source": [
    "#ID 9(2)\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name in benchmark_datasets_list:  # loading benchmark's datasets\n",
    "    datasets[dataset_name]=load_dataset(dataset_name,anomaly_dataset=False,preprocess_classification_dataset=False,dataset_folder=dataset_folder)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad12196",
   "metadata": {
    "id": "7ad12196"
   },
   "source": [
    "# **3. PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x-q3roMEtFfJ",
   "metadata": {
    "id": "x-q3roMEtFfJ"
   },
   "source": [
    "The  resizing of images(only when dataset is downloaded using URL) and scaling of images has already been performed while loading the datasets as shown in previous the Sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Balwbv2ANnT-",
   "metadata": {
    "id": "Balwbv2ANnT-"
   },
   "source": [
    "Standard preprocessing steps like deleting columns, encoding categorical values differently, or removing missing values do not apply to image data. Therefore, these methods (as well as own preprocessing steps and how these are captured) are covered in the tabular dataset benchmarks.\n",
    "\n",
    "Here, we only show two preprocessing steps that are applied to datasets stored in `datasets` dictionary(loaded in 2.2), which can also be performed individually depending upon requirement :\n",
    "- `Scale` all values by `1/255`.\n",
    "- `Transform the dataset into an anomaly dataset` for unsupervised anomaly detection by setting the class label `0` to normal and all other class labels to anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "FhPX8wPfNmwF",
   "metadata": {
    "id": "FhPX8wPfNmwF",
    "outputId": "ec16404b-0d29-4bae-e5c9-e4ee5e438d0d"
   },
   "outputs": [],
   "source": [
    "#ID 10(3)                            SCALING APPLIED\n",
    "\n",
    "#used imports from #ID 2(1)                                          \n",
    "for dataset_name in datasets:\n",
    "    \n",
    "    datasets[dataset_name].scale(scaling_factor=1/255)\n",
    "    operations=datasets[dataset_name].operations_performed\n",
    "    dataset_info_store(dataset_name,new_recipe_path,info_type='standard_functions',content=operations) \n",
    "   \n",
    "\n",
    "\n",
    "#print(\"Scaling performed on datasets!\")    \n",
    "#print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZUpLqmtsyGc",
   "metadata": {
    "id": "IZUpLqmtsyGc"
   },
   "source": [
    "The file <b>f\"{time}-{benchmark_name}-{benchmark_type}-recipe.yaml\"</b> now contains information about how to preprocess(i.e. perform scaling) the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "DWm4l0mUstgE",
   "metadata": {
    "id": "DWm4l0mUstgE",
    "outputId": "5519f8cf-7f05-4a88-8c53-75382ee30475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myImageDataset:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "mvtec_ad_transistor:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n"
     ]
    }
   ],
   "source": [
    "#ID 11(3)\n",
    "\n",
    "!cat {new_recipe_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZSTGiI5Qsi6e",
   "metadata": {
    "id": "ZSTGiI5Qsi6e",
    "outputId": "9ea47a01-a842-44ff-d192-6cd9e1627b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets after adding anomaly-conversion datasets: \n",
      "{'myImageDataset': <oab.data.unsupervised.UnsupervisedAnomalyDataset object at 0x7f87b9fa8e90>, 'mvtec_ad_transistor': <oab.data.unsupervised.UnsupervisedAnomalyDataset object at 0x7f87b9f94d90>}\n"
     ]
    }
   ],
   "source": [
    "#ID 12(3)                            ANOMALY-DATASET CONVERSION PERFORMED\n",
    "\n",
    "\n",
    "datasets_ad={}    \n",
    "    # for storing dataset objects converted to anomaly-dataset\n",
    "for dataset_name in datasets:   \n",
    "    \n",
    "     datasets_ad[dataset_name]= UnsupervisedAnomalyDataset(classification_dataset=datasets[dataset_name],\n",
    "                                                       normal_labels=0)  \n",
    "   \n",
    "     normal_labels=datasets_ad[dataset_name].normal_labels \n",
    "     dataset_info_store(dataset_name,new_recipe_path,info_type='anomaly_dataset',content=normal_labels)   \n",
    "                                                                            \n",
    "print(\"datasets after adding anomaly-conversion datasets: \")    \n",
    "print(datasets_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4HSf5lCJczbu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HSf5lCJczbu",
    "outputId": "8573e270-eb3c-4c2e-e399-084b104a21b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myImageDataset:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "mvtec_ad_transistor:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n"
     ]
    }
   ],
   "source": [
    "#ID 13(3)\n",
    "\n",
    "!cat {new_recipe_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f600e5a",
   "metadata": {
    "id": "4f600e5a"
   },
   "source": [
    "# **4. SAMPLING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817a6ab",
   "metadata": {
    "id": "f817a6ab"
   },
   "source": [
    "Here, we define the sampling parameters to sample from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bae62b9",
   "metadata": {
    "id": "6bae62b9",
    "outputId": "eb1b0b03-efa8-46d7-99fd-34dc771313e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'unsupervised_multiple': {'n': 25, 'contamination_rate': 0.5, 'n_steps': 10, 'apply_random_seed': True, 'keep_frequency_ratio_normals': False, 'equal_frequency_normals': False, 'keep_frequency_ratio_anomalies': False, 'equal_frequency_anomalies': False, 'flatten_images': False, 'shuffle': True, 'include_description': True}}]\n"
     ]
    }
   ],
   "source": [
    "#ID 14(4)\n",
    "\n",
    "### ADD YOUR OWN SAMPLING PARAMETERS ###\n",
    "\n",
    "# sampling parameters\n",
    "\n",
    "n=25                              #Number of data points to sample                    \n",
    "contamination_rate = 0.5         #Contamination rate when sampling, defaults to 0.05\n",
    "n_steps = 10                     #Number of samples to take, i.e., number of times sampling is repeated, defaults to 10   \n",
    "\n",
    "#These below are the possible sampling types to sample from datasets\n",
    "sampling_types=['unsupervised_multiple','unsupervised_single','unsupervised_multiple_benchmark']\n",
    "\n",
    "\n",
    "sampling_type='unsupervised_multiple'  #by default for this run\n",
    "\n",
    "sampling_params_current_run=[{'n':n,'contamination_rate':contamination_rate,'n_steps':n_steps,\n",
    "                             'apply_random_seed': True,\n",
    "                             'keep_frequency_ratio_normals': False,\n",
    "                             'equal_frequency_normals': False,\n",
    "                             'keep_frequency_ratio_anomalies': False,\n",
    "                             'equal_frequency_anomalies': False,\n",
    "                             'flatten_images': False,\n",
    "                              'shuffle': True,\n",
    "                             'include_description': True\n",
    "                             \n",
    "                             \n",
    "                             },sampling_type] \n",
    "\n",
    "sampling_data=[{sampling_type:sampling_params_current_run[0]}]\n",
    "print(sampling_data)\n",
    "\n",
    "for dataset_name in datasets_ad:\n",
    "    \n",
    "    dataset_info_store(dataset_name,new_recipe_path,'sampling',content=sampling_data)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZpZe-6r6tdIl",
   "metadata": {
    "id": "ZpZe-6r6tdIl"
   },
   "source": [
    "The above sampling parameters are utilized in\n",
    "<b>#ID 23(5)</b> \n",
    "for sampling the datasets(except the pre-installed mv_tec_ad_datasets) before training the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d171e56",
   "metadata": {
    "id": "2d171e56",
    "outputId": "82d3de15-5fbc-438b-f7ae-9398b17ec140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myImageDataset:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n",
      "mvtec_ad_transistor:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n"
     ]
    }
   ],
   "source": [
    "# ID 15(4)\n",
    "!cat {new_recipe_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbba70",
   "metadata": {
    "id": "73bbba70"
   },
   "source": [
    "Now, we will associate sampling information with each dataset loaded in the benchmark run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a49db16",
   "metadata": {
    "id": "3a49db16",
    "outputId": "a83a0e73-9603-4931-9bc3-542c2931d517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'myImageDataset': [<oab.data.unsupervised.UnsupervisedAnomalyDataset object at 0x7f87b9fa8e90>, [{'n': 25, 'contamination_rate': 0.5, 'n_steps': 10, 'apply_random_seed': True, 'keep_frequency_ratio_normals': False, 'equal_frequency_normals': False, 'keep_frequency_ratio_anomalies': False, 'equal_frequency_anomalies': False, 'flatten_images': False, 'shuffle': True, 'include_description': True}, 'unsupervised_multiple']], 'mvtec_ad_transistor': [<oab.data.unsupervised.UnsupervisedAnomalyDataset object at 0x7f87b9f94d90>, [{'n': 25, 'contamination_rate': 0.5, 'n_steps': 10, 'apply_random_seed': True, 'keep_frequency_ratio_normals': False, 'equal_frequency_normals': False, 'keep_frequency_ratio_anomalies': False, 'equal_frequency_anomalies': False, 'flatten_images': False, 'shuffle': True, 'include_description': True}, 'unsupervised_multiple']]}\n"
     ]
    }
   ],
   "source": [
    "#ID 16(4)\n",
    "benchmarking_datasets={}\n",
    "\n",
    "for (x,y) in datasets_ad.items():\n",
    "    benchmarking_datasets[x]=[y,sampling_params_current_run]\n",
    "\n",
    "\n",
    "print(benchmarking_datasets)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248c3ad",
   "metadata": {
    "id": "e248c3ad"
   },
   "source": [
    "The above dictionary <b>benchmarking_datasets</b> will be used for the Benchmarking as it contains all the information:\"\n",
    "    \n",
    "    \n",
    "    1.dataset_name\n",
    "    2.final_dataset_object(preprocessed and anomaly-converted)\n",
    "    3.sampling_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd1b0f",
   "metadata": {
    "id": "babd1b0f"
   },
   "source": [
    "\n",
    "\n",
    "# **5. ALGORITHM TRAINING AND TESTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3466bff",
   "metadata": {},
   "source": [
    "<b>To load own algorithm(s), refer to #ID 33(9) and #ID 34(9)</b> where an example algorithm is loaded, then \n",
    "\n",
    "come back to this cell  and <b>load own algorithm(s) details in #ID 17(5),#ID 18(5) AND #ID 19(5)</b> in the same way as benchmark algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tjmqC3lBaMwX",
   "metadata": {
    "id": "tjmqC3lBaMwX"
   },
   "source": [
    "We first download and import algorithms used for anomaly decection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "OZFq2XBfaMRN",
   "metadata": {
    "id": "OZFq2XBfaMRN",
    "outputId": "120455e9-8fb6-470a-cc1e-6863866be335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................] 1930 / 1930"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cae_KNN (4).py'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ID 17(5)\n",
    "\n",
    "import wget\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/ISDM-CAU-Kiel/oab/master/notebooks/benchmark_image/cae_ABOD.py', \"cae_ABOD.py\")\n",
    "wget.download('https://raw.githubusercontent.com/ISDM-CAU-Kiel/oab/master/notebooks/benchmark_image/cae_iforest.py', \"cae_iforest.py\")\n",
    "wget.download('https://raw.githubusercontent.com/ISDM-CAU-Kiel/oab/master/notebooks/benchmark_image/conv_ae.py', \"conv_ae.py\")\n",
    "wget.download('https://raw.githubusercontent.com/ISDM-CAU-Kiel/oab/master/notebooks/benchmark_image/cae_LOF.py', \"cae_LOF.py\")\n",
    "wget.download('https://raw.githubusercontent.com/ISDM-CAU-Kiel/oab/master/notebooks/benchmark_image/cae_KNN.py', \"cae_KNN.py\")\n",
    "\n",
    "\n",
    "### ADD your algo import here ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "NmVNOM7Uak1i",
   "metadata": {
    "id": "NmVNOM7Uak1i"
   },
   "outputs": [],
   "source": [
    "#ID 18(5)\n",
    "\n",
    "## ADD your algo(s) import here ###\n",
    "#from module_name import class_name\n",
    "\n",
    "\n",
    "# load all algorithms\n",
    "from conv_ae import ConvAutoEncoder\n",
    "from cae_ABOD import CAEABOD\n",
    "from cae_KNN import CAEKNN\n",
    "from cae_LOF import CAELOF\n",
    "from cae_iforest import CAEIForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637590bb",
   "metadata": {
    "id": "637590bb"
   },
   "source": [
    "Firstly, we define hyperparameters for all algorithms and choose for benchmarking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eef70b70",
   "metadata": {
    "id": "eef70b70"
   },
   "outputs": [],
   "source": [
    "#ID 19(5)\n",
    "\n",
    "   \n",
    "### Extend Algos dictionary with own algorithm specifications as shown below for OAB algorithms ###   \n",
    "\n",
    "### ADD YOUR OWN (HYPER)PARAMETERS AND THEIR VALUES FOR PRE-INSTALLED ALGOS###\n",
    "\n",
    "# CAE+KNN\n",
    "knn_factor = 0.05\n",
    "knn_minimum = 10\n",
    "\n",
    "\n",
    "# CAE+LOF\n",
    "lof_factor = 0.1\n",
    "lof_minimum = 10\n",
    "\n",
    "# CAE+ABOD\n",
    "abod_factor = 0.01\n",
    "abod_minimum = 10\n",
    "\n",
    "\n",
    "\n",
    "lst_benchmark_algorithms =[\n",
    "    {   \n",
    "       \"algo_module_name\": \"cae_ABOD\" , \n",
    "       \"algo_class_name\": \"CAEABOD\",\n",
    "       \"algo_name_in_result_table\": \"CAE v3\",\n",
    "       \"algo_parameters\": {\"CAE_parameters\": {'latent_dim': 100, 'epochs': 50, 'verbose': 0},\n",
    "                           \"ABOD_parameters\": {'n_neighbors':{'abod_factor':00.1 ,'abod_minimum':10 }}}, \n",
    "       \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "       \"decision_scores\": {'field_name': 'decision_scores_'}\n",
    "    }\n",
    "    \n",
    "       \n",
    "]\n",
    "'''\n",
    " ### uncomment to use these algos  for benchmarking\n",
    " ,  \n",
    " \n",
    " {\n",
    "       \"algo_module_name\": \"conv_ae\"   ,\n",
    "       \"algo_class_name\": \"ConvAutoEncoder\",\n",
    "       \"algo_name_in_result_table\": \"CAE v1\",\n",
    "       \"algo_parameters\":   {'latent_dim': 100, 'epochs': 50, 'verbose': 0},\n",
    "        \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "       \"decision_scores\": {'field_name': 'decision_scores_'}\n",
    "       } \n",
    " ,\n",
    "{\n",
    "       \"algo_module_name\": \"cae_iforest\",   \n",
    "       \"algo_class_name\": \"CAEIForest\",\n",
    "       \"algo_name_in_result_table\": \"CAE v2\",\n",
    "       \"algo_parameters\": {\"CAE_parameters\": {'latent_dim': 100, 'epochs': 50, 'verbose': 0}, \"IForest_parameters\": {'random_state': 42} },\n",
    "        \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "        \"decision_scores\": {'field_name': 'decision_scores_'}\n",
    "        }\n",
    "\n",
    " \n",
    "    ]\n",
    "\n",
    "    {   \n",
    "       \"algo_module_name\": \"cae_KNN\" , \n",
    "       \"algo_class_name\": \"CAEKNN\",\n",
    "       \"algo_name_in_result_table\": \"CAE v4\",\n",
    "       \"algo_parameters\": {\"CAE_parameters\": {'latent_dim': 100, 'epochs': 50, 'verbose': 0},\n",
    "                           \"KNN_parameters\": {'n_neighbors': {'knn_factor':0.05 ,'knn_minimum':10 }}},\n",
    "       \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "       \"decision_scores\": {'field_name': 'decision_scores_'}\n",
    "    },\n",
    "    \n",
    "    {   \n",
    "       \"algo_module_name\": \"cae_LOF\" , \n",
    "       \"algo_class_name\": \"CAELOF\",\n",
    "       \"algo_name_in_result_table\": \"CAE v5\",\n",
    "       \"algo_parameters\": {\"CAE_parameters\": {'latent_dim': 100, 'epochs': 50, 'verbose': 0},\n",
    "                           \"LOF_parameters\": {'n_neighbors': {'lof_factor':0.1 ,'lof_minimum':10 }}},\n",
    "       \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "       \"decision_scores\": {'field_name': 'decision_scores_'}\n",
    "    }\n",
    "    \n",
    "    \n",
    "]    \n",
    "'''    \n",
    "\n",
    "### ADD OWN ALGORITHMS NAME(S) with algorithm specifications as shown above for OAB algorithms ###   \n",
    "\n",
    "own_algorithms=[]   #add to this list e.g. { \"algo_module_name\": \"own_algo\" , \"algo_class_name\": \"ownAlgoClass\",..........\"decision_scores\": 'decision_scores_'} \n",
    "\n",
    "lst_benchmark_algorithms.extend(own_algorithms)\n",
    "\n",
    "\n",
    "#seed defined for ths benchmark run for obtaining consistent results \n",
    "seed=42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de5187",
   "metadata": {
    "id": "00de5187"
   },
   "source": [
    "<b>LOAD YOUR RECIPE</b> to be repdroduced and use it in the current benchmark run, lets,see  how it looks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38327e77",
   "metadata": {
    "id": "38327e77",
    "outputId": "7a093a77-07f8-4945-ee16-c701c9fd3a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: \r\n",
      "  - 42\r\n",
      "myImageDataset2:\r\n",
      "- dataset\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels: \r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098 \r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10 \r\n",
      "      flatten_images: false\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n",
      "\r\n",
      "conv_ae:\r\n",
      "- algo_name\r\n",
      "- init:\r\n",
      "    params:\r\n",
      "      latent_dim: 100\r\n",
      "      epochs: 50\r\n",
      "      verbose: 0\r\n",
      "  fit:\r\n",
      "    method_name: fit\r\n",
      "    params: {}\r\n",
      "  decision_scores:\r\n",
      "    field_name: decision_scores_\r\n",
      "    \r\n",
      "- ConvAutoEncoder\r\n"
     ]
    }
   ],
   "source": [
    "#ID 20(5)       # Execute this cell only when you already have a recipe file  to load from\n",
    "\n",
    "### ADD AN OPTIONAL RECIPE  PATH TO ADD TO THIS BENCHMARK RUN START ###   \n",
    "\n",
    "# Note: recipes of type \"unsupervised image(ssi) \" i.e. of the format: \n",
    "#               \"timestamp-benchmark_name-usi-recipe.yaml\"\n",
    "# can only be used for benchmarking in this notebook.\n",
    "\n",
    "recipe_path=\"Paper_B/20211210173000-Paper_B-usi-recipe.yaml\"\n",
    "\n",
    "### ADD AN OPTIONAL RECIPE  PATH TO ADD TO THIS BENCHMARK RUN END ###\n",
    " \n",
    "    \n",
    "    \n",
    "### UNCOMMENT ONLY IF NO NEW DATASETS WERE ADDED IN THE BENCHMARK EXCEPT FROM RECIPE START ###     \n",
    "\n",
    "#benchmarking_datasets={}\n",
    "#lst_benchmark_algorithms=[]\n",
    "\n",
    "### UNCOMMENT ONLY IF NO NEW DATASETS WERE ADDED IN THE BENCHMARK EXCEPT FROM RECIPE END ###  \n",
    "\n",
    "!cat {recipe_path} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7fa2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_ae----\n",
      "\n",
      "\n",
      "myImageDataset2------\n",
      "standard/custom preprocessing performed.\n",
      "transformed to anomaly dataset.\n"
     ]
    }
   ],
   "source": [
    "#ID 21(5)    # Execute this cell only when you already have a recipe file  to load from \n",
    "\n",
    "\n",
    "\n",
    "recipe_algos=data_from_recipe('algos',recipe_path) # all algo names from recipe extracted\n",
    "#print(f\"recipe_algos:\\n{recipe_algos}\")\n",
    "\n",
    "recipe_datasets=data_from_recipe('datasets',recipe_path) # all dataset info(anomaly dataset object/anomalydataset params/sampling params) is perfomed and obtained\n",
    "#print(f\"\\nrecipe_datasets:\\n{recipe_datasets}\")\n",
    " \n",
    "recipe_seed=data_from_recipe('seed',recipe_path)  # obtained seeds to feed in this benchmark \n",
    "seed=recipe_seed   # seed of current benchmark is overwritten by recipe seed\n",
    "\n",
    "# adding recipe_datasets to benchmarking_datasets\n",
    "for dataset_name in recipe_datasets:\n",
    "    benchmarking_datasets[dataset_name]=recipe_datasets[dataset_name][:2]\n",
    "#print(f\"benchmarking_datasets: {benchmarking_datasets}\") \n",
    "                                         \n",
    "#adding algos from recipe_algos to lst_benchmarking_algos\n",
    "for algo in recipe_algos:\n",
    "    #print(algo)\n",
    "    lst_benchmark_algorithms.append(algo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef08908",
   "metadata": {
    "id": "4ef08908",
    "outputId": "55a09390-24c1-47e1-bab9-37a84891604e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Datasets for this benchmark run:\n",
      "myImageDataset\n",
      "mvtec_ad_transistor\n",
      "myImageDataset2\n",
      "\n",
      "All algos for this benchmark run:\n",
      "cae_ABOD\n",
      "conv_ae\n"
     ]
    }
   ],
   "source": [
    "#ID 22(5)\n",
    "\n",
    "print(\"\\nAll Datasets for this benchmark run:\")    \n",
    "for dataset_name in benchmarking_datasets:\n",
    "    print(dataset_name)\n",
    "\n",
    "    \n",
    " \n",
    "print(\"\\nAll algos for this benchmark run:\")\n",
    "for algo in lst_benchmark_algorithms:\n",
    "    #print(algo)\n",
    "    print(algo['algo_module_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb76fd8",
   "metadata": {
    "id": "1eb76fd8"
   },
   "source": [
    "Now, For every benchmark dataset , we sample from that dataset to train the algorithms and then predict the outcomes for each dataset with each algortihm and then store results in a evaluation object, which is then added to the comparison object to show the final Benchmarking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0763aeb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0763aeb2",
    "outputId": "5b15015f-6bb6-4d74-f7ea-5ba4e7082c91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------myImageDataset-------\n",
      "------cae_ABOD\n",
      ".....WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879ddf03b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4769320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba577830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879da24680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4a9ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4a9ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.299 \t 0.067 \t\t roc_auc\n",
      "-0.163 \t 0.112 \t\t adjusted_average_precision\n",
      "0.410 \t 0.058 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      "------conv_ae\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4713440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879d59ecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4de7710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b47904d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4de7710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c09830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba247dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879dcdecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4a9ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c28440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.608 \t 0.119 \t\t roc_auc\n",
      "0.301 \t 0.199 \t\t adjusted_average_precision\n",
      "0.639 \t 0.106 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      "-------mvtec_ad_transistor-------\n",
      "------cae_ABOD\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba438cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba438d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba438c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879dd830e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c28680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879d5b0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4a9a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba577950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba438e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4736320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_transistor with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.535 \t 0.068 \t\t roc_auc\n",
      "0.269 \t 0.141 \t\t adjusted_average_precision\n",
      "0.630 \t 0.076 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      "------conv_ae\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4713440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4ba2050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b47b4440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4b1d0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba577d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b48110e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4b1dcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879d59eb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c09830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c09950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_transistor with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.391 \t 0.102 \t\t roc_auc\n",
      "0.044 \t 0.146 \t\t adjusted_average_precision\n",
      "0.518 \t 0.074 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      "-------myImageDataset2-------\n",
      "------cae_ABOD\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4b799e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879dc5ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4a8d170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba577dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4ba2a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b48e7320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b49a0b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b47699e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879da2b0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ca659440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset2 with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.465 \t 0.049 \t\t roc_auc\n",
      "0.051 \t 0.122 \t\t adjusted_average_precision\n",
      "0.511 \t 0.068 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      "------conv_ae\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b49a0f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879da2c290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b47b6ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4dc8d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f879da2b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b48e7830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b47130e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c28680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87ba577b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f87b4c283b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset2 with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.469 \t 0.082 \t\t roc_auc\n",
      "0.074 \t 0.157 \t\t adjusted_average_precision\n",
      "0.524 \t 0.085 \t\t precision_recall_auc\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ID 23(5)\n",
    "\n",
    "co = ComparisonObject()\n",
    " \n",
    "for dataset_name in list(benchmarking_datasets.keys()):\n",
    "    print(f'-------{dataset_name}-------') \n",
    "    \n",
    "    \n",
    "    for alg in lst_benchmark_algorithms:\n",
    "        \n",
    "        print(\"------\"+alg[\"algo_module_name\"])\n",
    "        eval_obj = EvaluationObject(algorithm_name=alg[\"algo_name_in_result_table\"])\n",
    "        \n",
    "        sampling_type=benchmarking_datasets[dataset_name][1][1]\n",
    "        sampling_params=benchmarking_datasets[dataset_name][1][0]\n",
    "        sampling_params['random_seed']=seed\n",
    "        \n",
    "        for (x,y),sample_config in sample_v3(dataset_name,sampling_type,sampling_params,benchmarking_datasets[dataset_name][0]):\n",
    "                \n",
    "                algorithm_params=algo_params(alg,l=len(x))               \n",
    "                algo= getattr(__import__(alg[\"algo_module_name\"]),alg[\"algo_class_name\"])(**algorithm_params) \n",
    "                print('.', end='') # update to see progress \n",
    "                getattr(algo,alg[\"fit\"][\"method_name\"])(x, **alg[\"fit\"][\"params\"])  # fitting algo\n",
    "                pred= getattr(algo,alg[\"decision_scores\"][\"field_name\"]) #decision scores returned\n",
    "                eval_obj.add(ground_truth=y, prediction=pred, description=sample_config)  \n",
    "                \n",
    "                \n",
    "        print(\"\\n\")    \n",
    "        eval_desc = eval_obj.evaluate(print=True, metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "        co.add_evaluation(eval_desc)\n",
    "        print(\"\\n\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c585e",
   "metadata": {
    "id": "501c585e"
   },
   "source": [
    "# **6. EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57beebf",
   "metadata": {
    "id": "e57beebf"
   },
   "source": [
    "Here , we will see how different metrics can be selected when evaluating an algorithm's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bc232",
   "metadata": {
    "id": "d05bc232"
   },
   "source": [
    "In previous section while creating an evalutation description,  we used all metrics for evaluation:\n",
    "\n",
    "     eval_desc = eval_obj.evaluate(print=False, metrics=all_metrics)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f97869e2",
   "metadata": {
    "id": "f97869e2",
    "outputId": "5b7a7df0-c7d2-46cb-dbb7-06e29350ba0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roc_auc', 'average_precision', 'adjusted_average_precision', 'precision_n', 'adjusted_precision_n', 'precision_recall_auc']\n"
     ]
    }
   ],
   "source": [
    "#ID 24(6)\n",
    "\n",
    "# to use a subset, first see which ones are available\n",
    "\n",
    "print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c32d570c",
   "metadata": {
    "id": "c32d570c"
   },
   "outputs": [],
   "source": [
    "#ID 25(6)\n",
    "\n",
    "#### ADD YOUR OWN NUMBER OF METRICS ###\n",
    "\n",
    "#Then we can  select an arbitrary subset\n",
    "metrics=['roc_auc', 'precision_recall_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39507d64",
   "metadata": {
    "id": "39507d64"
   },
   "source": [
    "# **7. SHOW BENCHMARK RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97932df",
   "metadata": {
    "id": "c97932df"
   },
   "source": [
    "We compare by printing, the results of the evaluations of different Algo-Dataset combinations.\n",
    "\n",
    "\\[Latex version: bold for highest, italics for second highest, ?\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e3a61a8",
   "metadata": {
    "id": "6e3a61a8",
    "outputId": "f5f765eb-3f2a-463b-b266-e00924cad805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                          0.299359             0.534615   \n",
      "ConvAutoEncoder                 0.608333             0.391026   \n",
      "Average                         0.453846             0.462821   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2  Average  \n",
      "CAE v3                           0.465385  0.43312  \n",
      "ConvAutoEncoder                  0.469231  0.48953  \n",
      "Average                          0.467308      NaN  \n",
      "For adjusted_average_precision:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                         -0.163056             0.269122   \n",
      "ConvAutoEncoder                 0.300590             0.043772   \n",
      "Average                         0.068767             0.156447   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                           0.051295  0.052454  \n",
      "ConvAutoEncoder                  0.074042  0.139468  \n",
      "Average                          0.062668       NaN  \n",
      "For precision_recall_auc:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                          0.409958             0.629839   \n",
      "ConvAutoEncoder                 0.638958             0.517692   \n",
      "Average                         0.524458             0.573765   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                           0.510632  0.516810  \n",
      "ConvAutoEncoder                  0.524197  0.560282  \n",
      "Average                          0.517415       NaN  \n"
     ]
    }
   ],
   "source": [
    "#ID 26(7)\n",
    "\n",
    "# print results in easily readable format\n",
    "co.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f3b0f46",
   "metadata": {
    "id": "6f3b0f46",
    "outputId": "3d4a09b9-cfd0-4ab8-c2a2-064072fc2f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                     0.299+-0.067        0.535+-0.068   \n",
      "ConvAutoEncoder            0.608+-0.119        0.391+-0.102   \n",
      "Average                           0.454               0.463   \n",
      "\n",
      "                mvtec_ad_myImageDataset2  Average  \n",
      "CAE v3                      0.465+-0.049  0.43312  \n",
      "ConvAutoEncoder             0.469+-0.082  0.48953  \n",
      "Average                            0.467      NaN  \n",
      "\n",
      "For adjusted_average_precision:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                    -0.163+-0.112        0.269+-0.141   \n",
      "ConvAutoEncoder            0.301+-0.199        0.044+-0.146   \n",
      "Average                           0.069               0.156   \n",
      "\n",
      "                mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                      0.051+-0.122  0.052454  \n",
      "ConvAutoEncoder             0.074+-0.157  0.139468  \n",
      "Average                            0.063       NaN  \n",
      "\n",
      "For precision_recall_auc:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                     0.410+-0.058        0.630+-0.076   \n",
      "ConvAutoEncoder            0.639+-0.106        0.518+-0.074   \n",
      "Average                           0.524               0.574   \n",
      "\n",
      "                mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                      0.511+-0.068  0.516810  \n",
      "ConvAutoEncoder             0.524+-0.085  0.560282  \n",
      "Average                            0.517       NaN  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ID 27(7)\n",
    "\n",
    "# print results in easily readable format with standard deviations\n",
    "co.print_results(include_stdevs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sZfxpO-5UPfp",
   "metadata": {
    "id": "sZfxpO-5UPfp",
    "outputId": "4452e949-87c2-4a00-f543-96111c430ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & \\textit{0.299$\\pm$0.067} & \\textbf{0.535$\\pm$0.068} & \\textit{0.465$\\pm$0.049} & \\textit{0.433} \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.608$\\pm$0.119} & \\textit{0.391$\\pm$0.102} & \\textbf{0.469$\\pm$0.082} & \\textbf{0.490} \\\\\n",
      "  Average & 0.454 & 0.463 & 0.467 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "For adjusted_average_precision:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & \\textit{-0.163$\\pm$0.112} & \\textbf{0.269$\\pm$0.141} & \\textit{0.051$\\pm$0.122} & \\textit{0.052} \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.301$\\pm$0.199} & \\textit{0.044$\\pm$0.146} & \\textbf{0.074$\\pm$0.157} & \\textbf{0.139} \\\\\n",
      "  Average & 0.069 & 0.156 & 0.063 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "For precision_recall_auc:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & \\textit{0.410$\\pm$0.058} & \\textbf{0.630$\\pm$0.076} & \\textit{0.511$\\pm$0.068} & \\textit{0.517} \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.639$\\pm$0.106} & \\textit{0.518$\\pm$0.074} & \\textbf{0.524$\\pm$0.085} & \\textbf{0.560} \\\\\n",
      "  Average & 0.524 & 0.574 & 0.517 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ID 28(7)\n",
    "\n",
    "co.print_latex(include_stdevs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ZlXKXx64aAl",
   "metadata": {
    "id": "1ZlXKXx64aAl"
   },
   "source": [
    "# **8. REPRODUCIBILITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eBbV_ZNYiiC",
   "metadata": {
    "id": "7eBbV_ZNYiiC"
   },
   "source": [
    " ## **8.1 Creating recipes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zWTe3BI5Gfyz",
   "metadata": {
    "id": "zWTe3BI5Gfyz"
   },
   "source": [
    "This section shows **how `oab` can be used to make sampling results easily reproducible** .\n",
    " \n",
    "\n",
    "`yaml` files play an integral role in making reproducibility work, as they store the operations and parameters performed on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c0a73",
   "metadata": {
    "id": "dc4c0a73"
   },
   "source": [
    "We will see how to produce a recipe(.yaml) of the Benchmarkrun already performed  in <b>#ID 23(5)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827f5fb",
   "metadata": {
    "id": "e827f5fb"
   },
   "source": [
    "In <b>#ID 10(3) #ID 12(3) #ID 14(4)</b>,  We already performed operations on own datasets and OAB's datasets, and then already stored the daasets information as we can see below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff4c5cf3",
   "metadata": {
    "id": "ff4c5cf3",
    "outputId": "eae501b9-9947-4f1a-c911-d3000fa33f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myImageDataset:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n",
      "mvtec_ad_transistor:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n"
     ]
    }
   ],
   "source": [
    "#ID 29(8)\n",
    "!cat {new_recipe_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca638c8",
   "metadata": {
    "id": "5ca638c8"
   },
   "source": [
    "Now, we will store the information of  datasets and algorithms information from <b>Paper_B's</b> recipe\n",
    "and only of the algorithms of this benchmark in the new recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48159739",
   "metadata": {
    "id": "48159739"
   },
   "outputs": [],
   "source": [
    "#ID 30(8)        # Execute this cell only when you already loaded datasets from a recipe file\n",
    "# adding datasets from recipe used in in benchmark run in #ID 23(5)\n",
    "for dataset_name in recipe_datasets:\n",
    "    \n",
    "    \n",
    "    #storing anomaly parameters\n",
    "    dataset_info_store(dataset_name,new_recipe_path,info_type='anomaly_dataset',content=recipe_datasets[dataset_name][0].normal_labels)\n",
    "    \n",
    "    # storing preprocesing parameters\n",
    "    dataset_info_store(dataset_name,new_recipe_path,info_type='standard_functions',content=recipe_datasets[dataset_name][3]) \n",
    "    #dataset_info_store(dataset_name,new_recipe_path,info_type='custom_functions',content=recipe_datasets[dataset_name][4]) \n",
    "    \n",
    "    \n",
    "    #storing sampling parameters\n",
    "    if dataset_name[:9]!='mvtec_ad_':\n",
    "      sampling_data=recipe_datasets[dataset_name][1]\n",
    "      dataset_info_store(dataset_name,new_recipe_path,'sampling',content=sampling_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe5ffa",
   "metadata": {
    "id": "5dbe5ffa"
   },
   "source": [
    "Now,we will store information about <b>Algorithms and their hyperparameters</b> in the recipe(.yaml) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce1e6fd1",
   "metadata": {
    "id": "ce1e6fd1"
   },
   "outputs": [],
   "source": [
    "# 31(8)\n",
    "\n",
    "# storing information of all algorithms and seed in the recipe\n",
    "algorithms_info_store('unsupervised',lst_benchmark_algorithms,new_recipe_path)\n",
    "\n",
    "seed_info_store(seed,new_recipe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a989a8f5",
   "metadata": {
    "id": "a989a8f5",
    "outputId": "212bd717-5871-467b-b30c-a6a6964ad482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myImageDataset:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n",
      "mvtec_ad_transistor:\r\n",
      "- dataset\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- sampling:\r\n",
      "    unsupervised_multiple:\r\n",
      "      n: 25\r\n",
      "      contamination_rate: 0.5\r\n",
      "      n_steps: 10\r\n",
      "      apply_random_seed: true\r\n",
      "      keep_frequency_ratio_normals: false\r\n",
      "      equal_frequency_normals: false\r\n",
      "      keep_frequency_ratio_anomalies: false\r\n",
      "      equal_frequency_anomalies: false\r\n",
      "      flatten_images: false\r\n",
      "      shuffle: true\r\n",
      "      include_description: true\r\n",
      "myImageDataset2:\r\n",
      "- dataset\r\n",
      "- anomaly_dataset:\r\n",
      "    arguments:\r\n",
      "      normal_labels:\r\n",
      "      - 0\r\n",
      "      anomaly_labels:\r\n",
      "- standard_functions:\r\n",
      "  - name: scale\r\n",
      "    parameters:\r\n",
      "      scaling_factor: 0.00392156862745098\r\n",
      "- sampling:\r\n",
      "    n: 25\r\n",
      "    contamination_rate: 0.5\r\n",
      "    n_steps: 10\r\n",
      "    flatten_images: false\r\n",
      "    apply_random_seed: true\r\n",
      "    keep_frequency_ratio_normals: false\r\n",
      "    equal_frequency_normals: false\r\n",
      "    keep_frequency_ratio_anomalies: false\r\n",
      "    equal_frequency_anomalies: false\r\n",
      "    shuffle: true\r\n",
      "    include_description: true\r\n",
      "    random_seed: 42\r\n",
      "cae_ABOD:\r\n",
      "- algo_name\r\n",
      "- init:\r\n",
      "    params:\r\n",
      "      CAE_parameters:\r\n",
      "        latent_dim: 100\r\n",
      "        epochs: 50\r\n",
      "        verbose: 0\r\n",
      "      ABOD_parameters:\r\n",
      "        n_neighbors:\r\n",
      "          abod_factor: 0.1\r\n",
      "          abod_minimum: 10\r\n",
      "  fit:\r\n",
      "    method_name: fit\r\n",
      "    params: {}\r\n",
      "  decision_scores:\r\n",
      "    field_name: decision_scores_\r\n",
      "- CAEABOD\r\n",
      "conv_ae:\r\n",
      "- algo_name\r\n",
      "- init:\r\n",
      "    params:\r\n",
      "      latent_dim: 100\r\n",
      "      epochs: 50\r\n",
      "      verbose: 0\r\n",
      "  fit:\r\n",
      "    method_name: fit\r\n",
      "    params: {}\r\n",
      "  decision_scores:\r\n",
      "    field_name: decision_scores_\r\n",
      "- ConvAutoEncoder\r\n",
      "seed:\r\n",
      "- 42\r\n"
     ]
    }
   ],
   "source": [
    "#ID 32(8)\n",
    "!cat {new_recipe_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ef1QSaxHGgr0",
   "metadata": {
    "id": "Ef1QSaxHGgr0"
   },
   "source": [
    "In **f\"{time}-{benchmark_name}-{benchmark_type}-recipe.yaml\"**, we now see the sampling parameters, anomaly- dataset-conversion parameters, hyperparamters along with the algorithms for sampling type \"unsupervised_multiple\". If sampling is done in a different scenario, e.g., semisupervised_ train_multiple_split, this would also be stored in f\"{benchmark_name}/{time}-{benchmark_name}-{benchmark_type}-recipe.yaml\" using a different key in the sampling dict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U7PSnotYJIr2",
   "metadata": {
    "id": "U7PSnotYJIr2"
   },
   "source": [
    "### 2. Reproducing the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71159158",
   "metadata": {
    "id": "71159158",
    "outputId": "d37a18ec-5285-46ad-b379-2147cb9d2c98",
    "scrolled": false
   },
   "source": [
    "To reproduce the recipe created in the previous section,\n",
    "we refer to <b>Section 5 #ID 20(5)</b> where we can reproduce the run as well as extend benchmarks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ieghRWumgNY9",
   "metadata": {
    "id": "ieghRWumgNY9"
   },
   "source": [
    "# **9. EXTEND EXISTING BENCHMARK(own algorithm)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1HfN4e3PMn0",
   "metadata": {
    "id": "i1HfN4e3PMn0"
   },
   "source": [
    "To extend the existing benchmark here basically means to add  our own algorithm to the benchmark and to show the comparison results of pre-installed algorithms while also loading our own dataset.\n",
    "\n",
    "\n",
    "1. We load the datasets. To know how to do that, we can refer to  **Section \"1. Data\" and \"2. Data Selection\"**\n",
    "2. Then, load own algorithm as we will see in the next sub-section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kAAV6vAOy9-k",
   "metadata": {
    "id": "kAAV6vAOy9-k"
   },
   "source": [
    "## **9.1 Loading own Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cT1MEn7zSta",
   "metadata": {
    "id": "3cT1MEn7zSta"
   },
   "source": [
    "In this subsection 5.1, you will see **how an own unsupervised anomaly detection algorithm** can easily be used within oab to be evaluated. We will see how a class representing an algorithm can be structured and how its performance is evaluated.\n",
    "\n",
    "Of course, this is not the only way to use the functionality provided by oab. We do consider it to be the simplest way however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "r7jxQhkcze5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7jxQhkcze5d",
    "outputId": "c7d5d85b-dee5-41cc-f24e-49da6f14594e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                              ]   0 / 204\r",
      "100% [..............................................................] 204 / 204import numpy as np\r\n",
      "\r\n",
      "class RandomGuesser():\r\n",
      "\r\n",
      "    def fit(self, X):\r\n",
      "        \"Assign a random number to each sample\"\r\n",
      "        n_samples = X.shape[0]\r\n",
      "        self.decision_scores_ = np.random.randn(n_samples)\r\n"
     ]
    }
   ],
   "source": [
    "#ID 33(9)\n",
    "\n",
    "# download example algorithm and inspect content\n",
    "import wget\n",
    "wget.download('https://raw.githubusercontent.com/jandeller/test/main/RandomGuesser.py', \"RandomGuesser.py\")\n",
    "!cat RandomGuesser.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enGFFsQpRJ2Y",
   "metadata": {
    "id": "enGFFsQpRJ2Y"
   },
   "source": [
    "The sample `RandomGuesser` algorithm shown here is - as the name suggests - a random guesser, i.e., it assigns random anomaly scores to the samples.\n",
    "\n",
    "An algorithm used for unsupervised anomaly detection needs to specify a `fit(X_train)` method for training and a `decision_scores_` variable for inference that returns an anomaly score per data point in the test set.\n",
    "\n",
    "It is of course possible to rename the method and field, use a method for accessing the anomaly scores, etc. Note that if this is done, the following code has to be changed accordingly. Adhering to the conventions described above (`fit(X_train)` and `decision_scores_`) allows you to use the same interface as algorithms from [`PyOD`](https://pyod.readthedocs.io/en/latest/) as shown when [comparing algorithms using `oab`](https://colab.research.google.com/drive/1aV_itaYCJgzdZ1lQ7SUyHQ7z01xSPxDN?usp=sharing#scrollTo=QnAfCGTGL7xv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Y4FYSMtIzsqZ",
   "metadata": {
    "id": "Y4FYSMtIzsqZ",
    "outputId": "ed57bff9-0489-4519-d07b-f19058da63a3"
   },
   "outputs": [],
   "source": [
    "#ID 34(9)\n",
    "# used imports from #ID 2(0),#ID 17(5)\n",
    "#used sampling parameters from #ID 13(4)\n",
    "\n",
    "# and import the RandomGuesser\n",
    "from RandomGuesser import RandomGuesser\n",
    "\n",
    "own_algorithms=[{\n",
    "    \n",
    "       ### ADD YOUR OWN ALGO DETAILS IN THIS FORM ###\n",
    "       \"algo_module_name\": \"RandomGuesserSemisupervised\",   \n",
    "       \"algo_class_name\": \"RandomGuesserSemisupervised\",\n",
    "       \"algo_name_in_result_table\": \"RandomGuesserSemisupervised\",\n",
    "       \"algo_parameters\": {},\n",
    "        \"fit\": {'method_name': 'fit', 'params': {}}, \n",
    "        \"decision_SCORES\": {'field_name': 'decision_scores_'}\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22dcd4",
   "metadata": {},
   "source": [
    "The `own_algorithms` list in the above cell #ID 34(9) can be added to `lst_benchmarking_algos` as mentioned in #ID 19(5) to use this algorithm in a benchmark run shown in #ID 23(5) along with other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "RU5K81TC0PmQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RU5K81TC0PmQ",
    "outputId": "e0c6a548-76be-46f2-f4be-4696efa51fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.491 \t 0.109 \t\t roc_auc\n",
      "0.085 \t 0.179 \t\t adjusted_average_precision\n",
      "0.526 \t 0.092 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      ". . . . . . . . . . \n",
      "\n",
      "Evaluation on dataset mvtec_ad_transistor with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.515 \t 0.090 \t\t roc_auc\n",
      "0.135 \t 0.157 \t\t adjusted_average_precision\n",
      "0.557 \t 0.083 \t\t precision_recall_auc\n",
      "\n",
      "\n",
      ". . . . . . . . . . \n",
      "\n",
      "Evaluation on dataset mvtec_ad_myImageDataset2 with normal labels [0] and anomaly labels [1.0].\n",
      "Total of 10 datasets. Per dataset:\n",
      "25 instances, contamination_rate 0.5.\n",
      "Mean \t Std_dev \t Metric\n",
      "0.511 \t 0.109 \t\t roc_auc\n",
      "0.140 \t 0.202 \t\t adjusted_average_precision\n",
      "0.561 \t 0.102 \t\t precision_recall_auc\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ID 35(9)\n",
    "\n",
    "#  A comparison object is created for comparing the evaluations of different Algo-Dataset combinations\n",
    "co = ComparisonObject()\n",
    "\n",
    "for dataset_name in benchmarking_datasets:\n",
    "  # evaluate the random guesser\n",
    "  eval_obj = EvaluationObject(algorithm_name=\"RandomGuesser\")\n",
    "  for (x,y), settings in benchmarking_datasets[dataset_name][0].sample_multiple(n=n, \n",
    "                                                                  contamination_rate=contamination_rate, \n",
    "                                                                 n_steps=n_steps):\n",
    "      print(\".\", end=\" \") # update to see progress\n",
    "      rg = RandomGuesser()\n",
    "      rg.fit(x) # data is fitted to RandomGuesser\n",
    "      pred = rg.decision_scores_ # and decision_scores_ is accessed\n",
    "      eval_obj.add(y, pred, settings)\n",
    "  print(\"\\n\")\n",
    "  eval_desc = eval_obj.evaluate(metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "  # added to comparison object\n",
    "  co.add_evaluation(eval_desc)\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CHYWyeKKxs9M",
   "metadata": {
    "id": "CHYWyeKKxs9M"
   },
   "source": [
    "As in the above code, We store the evaluations of our own algorithm in evaluation object which is then added to comparison object.Similarly, we can create evaluation objects for other algorithms and add them to comparison object for final benchmarking  as shown in Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k-8sW1dvTcNj",
   "metadata": {
    "id": "k-8sW1dvTcNj"
   },
   "source": [
    "Finally, we show below the benchmarking results of our algorithm as described in \"**Section 7. Show Benchmarking Results**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "_RxojZg5zDhb",
   "metadata": {
    "id": "_RxojZg5zDhb",
    "outputId": "367c88df-594e-4e66-c709-6dc7003c0ac5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                          0.299359             0.534615   \n",
      "ConvAutoEncoder                 0.608333             0.391026   \n",
      "RandomGuesser                   0.491026             0.514744   \n",
      "Average                         0.466239             0.480128   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                           0.465385  0.433120  \n",
      "ConvAutoEncoder                  0.469231  0.489530  \n",
      "RandomGuesser                    0.510897  0.505556  \n",
      "Average                          0.481838       NaN  \n",
      "For adjusted_average_precision:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                         -0.163056             0.269122   \n",
      "ConvAutoEncoder                 0.300590             0.043772   \n",
      "RandomGuesser                   0.085105             0.135493   \n",
      "Average                         0.074213             0.149462   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                           0.051295  0.052454  \n",
      "ConvAutoEncoder                  0.074042  0.139468  \n",
      "RandomGuesser                    0.140398  0.120332  \n",
      "Average                          0.088578       NaN  \n",
      "For precision_recall_auc:\n",
      "                 mvtec_ad_myImageDataset  mvtec_ad_transistor  \\\n",
      "CAE v3                          0.409958             0.629839   \n",
      "ConvAutoEncoder                 0.638958             0.517692   \n",
      "RandomGuesser                   0.526395             0.556593   \n",
      "Average                         0.525104             0.568041   \n",
      "\n",
      "                 mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                           0.510632  0.516810  \n",
      "ConvAutoEncoder                  0.524197  0.560282  \n",
      "RandomGuesser                    0.561166  0.548052  \n",
      "Average                          0.531998       NaN  \n"
     ]
    }
   ],
   "source": [
    "#ID 36(9)\n",
    "\n",
    "# print results in easily readable format\n",
    "co.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1717c96b",
   "metadata": {
    "id": "1717c96b",
    "outputId": "98f83fc9-6661-4b94-c5df-c907831c3f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                     0.299+-0.067        0.535+-0.068   \n",
      "ConvAutoEncoder            0.608+-0.119        0.391+-0.102   \n",
      "RandomGuesser              0.491+-0.109        0.515+-0.090   \n",
      "Average                           0.466               0.480   \n",
      "\n",
      "                mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                      0.465+-0.049  0.433120  \n",
      "ConvAutoEncoder             0.469+-0.082  0.489530  \n",
      "RandomGuesser               0.511+-0.109  0.505556  \n",
      "Average                            0.482       NaN  \n",
      "\n",
      "For adjusted_average_precision:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                    -0.163+-0.112        0.269+-0.141   \n",
      "ConvAutoEncoder            0.301+-0.199        0.044+-0.146   \n",
      "RandomGuesser              0.085+-0.179        0.135+-0.157   \n",
      "Average                           0.074               0.149   \n",
      "\n",
      "                mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                      0.051+-0.122  0.052454  \n",
      "ConvAutoEncoder             0.074+-0.157  0.139468  \n",
      "RandomGuesser               0.140+-0.202  0.120332  \n",
      "Average                            0.089       NaN  \n",
      "\n",
      "For precision_recall_auc:\n",
      "                mvtec_ad_myImageDataset mvtec_ad_transistor  \\\n",
      "CAE v3                     0.410+-0.058        0.630+-0.076   \n",
      "ConvAutoEncoder            0.639+-0.106        0.518+-0.074   \n",
      "RandomGuesser              0.526+-0.092        0.557+-0.083   \n",
      "Average                           0.525               0.568   \n",
      "\n",
      "                mvtec_ad_myImageDataset2   Average  \n",
      "CAE v3                      0.511+-0.068  0.516810  \n",
      "ConvAutoEncoder             0.524+-0.085  0.560282  \n",
      "RandomGuesser               0.561+-0.102  0.548052  \n",
      "Average                            0.532       NaN  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ID 37(9)\n",
    "# print results in easily readable format with standard deviations\n",
    "co.print_results(include_stdevs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a75770e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For roc_auc:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & 0.299$\\pm$0.067 & \\textbf{0.535$\\pm$0.068} & 0.465$\\pm$0.049 & 0.433 \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.608$\\pm$0.119} & 0.391$\\pm$0.102 & \\textit{0.469$\\pm$0.082} & \\textit{0.490} \\\\\n",
      "  RandomGuesser & \\textit{0.491$\\pm$0.109} & \\textit{0.515$\\pm$0.090} & \\textbf{0.511$\\pm$0.109} & \\textbf{0.506} \\\\\n",
      "  Average & 0.466 & 0.480 & 0.482 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "For adjusted_average_precision:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & -0.163$\\pm$0.112 & \\textbf{0.269$\\pm$0.141} & 0.051$\\pm$0.122 & 0.052 \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.301$\\pm$0.199} & 0.044$\\pm$0.146 & \\textit{0.074$\\pm$0.157} & \\textbf{0.139} \\\\\n",
      "  RandomGuesser & \\textit{0.085$\\pm$0.179} & \\textit{0.135$\\pm$0.157} & \\textbf{0.140$\\pm$0.202} & \\textit{0.120} \\\\\n",
      "  Average & 0.074 & 0.149 & 0.089 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "For precision_recall_auc:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{  c c c c c  }\n",
      "  & mvtec\\_ad\\_myImageDataset & mvtec\\_ad\\_transistor & mvtec\\_ad\\_myImageDataset2 & Average \\\\\n",
      "  CAE v3 & 0.410$\\pm$0.058 & \\textbf{0.630$\\pm$0.076} & 0.511$\\pm$0.068 & 0.517 \\\\\n",
      "  ConvAutoEncoder & \\textbf{0.639$\\pm$0.106} & 0.518$\\pm$0.074 & \\textit{0.524$\\pm$0.085} & \\textbf{0.560} \\\\\n",
      "  RandomGuesser & \\textit{0.526$\\pm$0.092} & \\textit{0.557$\\pm$0.083} & \\textbf{0.561$\\pm$0.102} & \\textit{0.548} \\\\\n",
      "  Average & 0.525 & 0.568 & 0.532 &    \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ID 38(9)\n",
    "\n",
    "co.print_latex(include_stdevs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc535a8",
   "metadata": {
    "id": "0bc535a8"
   },
   "source": [
    "So,This was our example algorithm. Other algorithms can be used to run and extend benchmarks,   Please refer  to <b>5. ALGORITHM TRAINING AND TESTING</b>."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Unsupervised_Anomaly_Detection_on_Benchmark_Image_Data_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "oab",
   "language": "python",
   "name": "oab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
