{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNB9yVw0ms5c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfUXz_DDm1Gq"
   },
   "outputs": [],
   "source": [
    "from oab.data.load_dataset import load_dataset\n",
    "from oab.evaluation import EvaluationObject, ComparisonObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0t7NclLm1Jx"
   },
   "outputs": [],
   "source": [
    "# load all algorithms\n",
    "from cae_ocsvm import CAEOCSVM\n",
    "from cae_iforest import CAEIForest\n",
    "from conv_ae import ConvAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_n-x7QEm1Mw"
   },
   "outputs": [],
   "source": [
    "# define hyperparameters for all algorithms\n",
    "CAE_parameters = {'latent_dim': 100, 'epochs': 50, 'verbose': 0}\n",
    "\n",
    "names_to_parameters = {\n",
    "    'ocsvm': {'degree': 3},\n",
    "    'iforest': {'random_state': 42},\n",
    "}\n",
    "\n",
    "algo_names = [\n",
    "    'caeocsvm', \n",
    "    'caeiforest', \n",
    "    'cae'\n",
    "]\n",
    "\n",
    "name_to_init = {\n",
    "    'cae': ConvAutoEncoder,\n",
    "    'caeocsvm': CAEOCSVM,\n",
    "    'caeiforest': CAEIForest,\n",
    "}\n",
    "\n",
    "name_to_init_params = {\n",
    "    'cae': CAE_parameters,\n",
    "    'caeocsvm': {'CAE_parameters': CAE_parameters, 'OCSVM_parameters': names_to_parameters['ocsvm']},\n",
    "    'caeiforest': {'CAE_parameters': CAE_parameters, 'IForest_parameters': names_to_parameters['iforest']},    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL47QxG0qz9d"
   },
   "outputs": [],
   "source": [
    "dataset_names = ['mnist', 'cifar10', 'mvtec_ad_transistor', 'mvtec_ad_screw', 'mvtec_ad_pill', 'mvtec_ad_carpet', 'mvtec_ad_hazelnut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lePeZOYnITTS"
   },
   "outputs": [],
   "source": [
    "# sampling parameters\n",
    "training_split = 0.7\n",
    "max_contamination_rate = 0.5\n",
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nig55uXzG6Vn",
    "outputId": "b4f0ae1d-d61c-4b7c-fb0f-693266442ac4"
   },
   "outputs": [],
   "source": [
    "co = ComparisonObject() # object that collects all results\n",
    "\n",
    "# MNIST\n",
    "mnist = load_dataset('mnist', semisupervised=True)\n",
    "for algorithm_name in algo_names:\n",
    "    print(f\"---{algorithm_name}\") # update to see progress\n",
    "    init = name_to_init[algorithm_name]\n",
    "    eval_obj = EvaluationObject(algorithm_name=algorithm_name) # object that collects results for one algorithm on one data set\n",
    "    for (x_train, x_test, y_test), sample_config in mnist.sample_multiple_with_training_split(training_split=training_split, \n",
    "                                                                                    max_contamination_rate=max_contamination_rate, \n",
    "                                                                                    n_steps=n_steps,\n",
    "                                                                                    flatten_images=False):\n",
    "        print('.', end='') # update to see progress\n",
    "        algo = init(**name_to_init_params[algorithm_name])\n",
    "        algo.fit(x_train)\n",
    "        pred = algo.decision_function(x_test)\n",
    "        eval_obj.add(ground_truth=y_test, prediction=pred, description=sample_config)\n",
    "    eval_desc = eval_obj.evaluate(print=False, metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "    co.add_evaluation(eval_desc) # append evaluation of one algorithm on one data set to object that collects all results\n",
    "\n",
    "del mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM3c7U1_HAk9",
    "outputId": "18e41688-4929-4b95-d201-2f4c5493fd3e"
   },
   "outputs": [],
   "source": [
    "# CIFAR10\n",
    "cifar10 = load_dataset('cifar10', semisupervised=True)\n",
    "for algorithm_name in algo_names:\n",
    "    print(f\"---{algorithm_name}\") # update to see progress\n",
    "    init = name_to_init[algorithm_name]\n",
    "    eval_obj = EvaluationObject(algorithm_name=algorithm_name)\n",
    "    for (x_train, x_test, y_test), sample_config in cifar10.sample_multiple_with_training_split(training_split=training_split, \n",
    "                                                                                    max_contamination_rate=max_contamination_rate, \n",
    "                                                                                    n_steps=n_steps,\n",
    "                                                                                    flatten_images=False):\n",
    "        print('.', end='') # update to see progress\n",
    "        algo = init(**name_to_init_params[algorithm_name])\n",
    "        algo.fit(x_train)\n",
    "        pred = algo.decision_function(x_test)\n",
    "        eval_obj.add(ground_truth=y_test, prediction=pred, description=sample_config)\n",
    "    eval_desc = eval_obj.evaluate(print=False, metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "    co.add_evaluation(eval_desc)\n",
    "\n",
    "del cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtwcmgAXHSzw",
    "outputId": "080258ca-965f-482b-89f6-71a9e0dbb389"
   },
   "outputs": [],
   "source": [
    "# MVTec AD data sets already have a train test split, and that train test split is used here\n",
    "for mvtec_dataset_name in ['mvtec_ad_transistor', 'mvtec_ad_screw', 'mvtec_ad_pill', 'mvtec_ad_carpet', 'mvtec_ad_hazelnut']\n",
    "    dataset = load_dataset(mvtec_dataset_name, semisupervised=True)\n",
    "    print(f\"{mvtec_dataset_name}\") # update to see progress\n",
    "    for algorithm_name in algo_names:\n",
    "        print(f\"---{algorithm_name}\") # update to see progress\n",
    "        init = name_to_init[algorithm_name]\n",
    "        eval_obj = EvaluationObject(algorithm_name=algorithm_name)\n",
    "        (x_train, x_test, y_test), sample_config = dataset.sample_original_mvtec_split(flatten_images=False)\n",
    "        algo = init(**name_to_init_params[algorithm_name])\n",
    "        algo.fit(x_train)\n",
    "        pred = algo.decision_function(x_test)\n",
    "        eval_obj.add(ground_truth=y_test, prediction=pred, description=sample_config)\n",
    "            \n",
    "        eval_desc = eval_obj.evaluate(print=False, metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "        co.add_evaluation(eval_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "il41-xgjnA_a",
    "outputId": "58f15cc1-a7a2-4ae3-cb99-7ee7112c4f65"
   },
   "outputs": [],
   "source": [
    "co.print_results() # print results in human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiGtLvlonBCh",
    "outputId": "69bf224b-4808-4cfc-cb11-cdcac244da51"
   },
   "outputs": [],
   "source": [
    "co.print_latex() # print results as latex table"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Image_semisupervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
