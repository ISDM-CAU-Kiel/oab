{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RRyzqGZIhq6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDFT9oz9LQdP"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# import function to load datasets\n",
    "from oab.data.load_dataset import load_dataset\n",
    "# import objects for evaluation\n",
    "from oab.evaluation import EvaluationObject, ComparisonObject\n",
    "\n",
    "# import anomaly detection algorithms from pyod\n",
    "from pyod.models.ocsvm import OCSVM # fit and decision_function\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9m0QTORzU_Z",
    "outputId": "4b16fea8-6ac3-40bd-ada5-94b70c42f14f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load datasets and store them in a list\n",
    "boston = load_dataset('boston', semisupervised=True)\n",
    "pageblocks = load_dataset('page-blocks', semisupervised=True)\n",
    "pulsar_star = load_dataset('pulsar_star', semisupervised=True)\n",
    "forest_cover = load_dataset('forest_cover', semisupervised=True)\n",
    "spambase = load_dataset('spambase', semisupervised=True)\n",
    "wilt = load_dataset('wilt', semisupervised=True)\n",
    "nasa = load_dataset('NASA_ground_data', semisupervised=True)\n",
    "\n",
    "\n",
    "datasets = [\n",
    "            boston, \n",
    "            pageblocks,\n",
    "            pulsar_star, \n",
    "            forest_cover, \n",
    "            spambase, \n",
    "            wilt, \n",
    "            nasa\n",
    "            ]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JoKATq-XX5l"
   },
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "names_to_algorithms = {'ocsvm': OCSVM, 'iforest': IForest, 'ae': AutoEncoder, 'pca': PCA, 'vae': VAE}\n",
    "\n",
    "names_to_parameters = {\n",
    "    'ocsvm': {'degree': 3}, # default parameter\n",
    "    'iforest': {'random_state': 42},\n",
    "    'pca': {'n_components': 0.9, 'svd_solver': 'full'},\n",
    "    'ae': {'verbose': 0, 'hidden_neurons': [6, 3, 3, 6], 'random_state': 42},\n",
    "    'vae': {'encoder_neurons': [6, 3], 'decoder_neurons': [3, 6], 'verbose': 0, 'random_state': 42},\n",
    "}\n",
    "\n",
    "algorithm_names = [\n",
    "                   'ocsvm',\n",
    "                   'iforest',\n",
    "                   'pca',\n",
    "                   'ae',\n",
    "                   'vae',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeiNzJtUSjFg"
   },
   "outputs": [],
   "source": [
    "# sampling parameters\n",
    "training_split = 0.7\n",
    "max_contamination_rate = 0.5\n",
    "n_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnAfCGTGL7xv",
    "outputId": "b58b0764-1dc8-4666-c2c9-6b38758357f0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# create comparison object that holds all evaluations\n",
    "co = ComparisonObject()\n",
    "\n",
    "\n",
    "# run algorithms on datasets\n",
    "for dataset in tqdm(datasets):\n",
    "\n",
    "    for algorithm_name in algorithm_names:\n",
    "        print(f\"-- Dataset name {dataset.classification_dataset.name}, algorithm {algorithm_name}\")\n",
    "        algorithm = names_to_algorithms[algorithm_name]\n",
    "        param_dict = names_to_parameters[algorithm_name]\n",
    "        # eval_obj stores predictions and ground truths\n",
    "        eval_obj = EvaluationObject(algorithm_name=algorithm_name)\n",
    "\n",
    "        # sample multiple times from each dataset\n",
    "        for (x_train, x_test, y_test), sample_config in dataset.sample_multiple_with_training_split(training_split=training_split, \n",
    "                                                                                                        max_contamination_rate=max_contamination_rate, \n",
    "                                                                                                        n_steps=n_steps):\n",
    "            # instantiate anomaly detection algorithm\n",
    "            if (algorithm_name == 'ae' or algorithm_name == 'vae'):\n",
    "                tf.random.set_seed(42)\n",
    "                np.random.seed(42)\n",
    "            algo = algorithm(**param_dict)\n",
    "            # fit data to algorithm\n",
    "            algo.fit(x_train)\n",
    "            # get prediction scores\n",
    "            pred = algo.decision_function(x_test)\n",
    "            # add ground truth and prediction to evaluation object\n",
    "            eval_obj.add(ground_truth=y_test, prediction=pred, description=sample_config)\n",
    "        # calculate mean values for metrics based on previously added ground truths\n",
    "        # and predictions\n",
    "        eval_desc = eval_obj.evaluate(print=False, metrics=['roc_auc', 'adjusted_average_precision', 'precision_recall_auc'])\n",
    "        # add resulting evaluation to the comparison object\n",
    "        co.add_evaluation(eval_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH9DL5HKL-WQ"
   },
   "outputs": [],
   "source": [
    "# print results in easily readable format\n",
    "co.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHkyCloWFCse",
    "outputId": "376a0c94-d936-4c27-bca3-b0a37d22c772"
   },
   "outputs": [],
   "source": [
    "# print results in easily readable format with standard deviations\n",
    "co.print_results(include_stdevs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fqi3fUTRL_NV",
    "outputId": "0649941e-dd95-40d1-b4ac-1d91256e7cda"
   },
   "outputs": [],
   "source": [
    "# print results in latex format (note: also has parameter include_stdevs)\n",
    "co.print_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "0_2Semisupervised_tabular_oneparameter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
